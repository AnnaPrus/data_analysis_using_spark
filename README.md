## Data Analysis Using Spark

## Project Overview

This project demonstrates hands-on data analysis using Apache Spark and PySpark. The workflow includes:

- Loading and structuring CSV data as a Spark DataFrame
- Defining an explicit schema for columns and data types
- Running Spark SQL queries and using DataFrame API transformations
- Solving business-oriented analytics tasks, such as:
  - Calculating average salary by department
  - Filtering employees by department or name patterns
  - Aggregating and joining data to answer key business questions




## Technologies Used

- Python
  - Primary programming language
- Apache Spark (PySpark)
  - Distributed data processing framework and API
- Spark SQL
  - SQL interface for structured data processing
- Jupyter Notebook (or compatible IDE)
  - Interactive, reproducible environment for analytics and demonstration
- findspark & wget
  - Library and command-line tool for integration and data download

---


